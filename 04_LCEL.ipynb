{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Courage is knowing what not to fear.\" - Plato'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a quote by the philosopher - {philosopher}\")\n",
    "parser = StrOutputParser()\n",
    "openai = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = prompt | openai | parser\n",
    "\n",
    "chain.invoke({\"philosopher\": \"Plato\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me a quote by the philosopher - Plato')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"philosopher\": \"Plato\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Courage is knowing what not to fear.\" - Plato', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 16, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5324e03d-f17f-41c0-8c86-97a8693fc8d1-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.invoke([HumanMessage(content=\"Tell me a quote by the philosopher - Plato\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plato was a philosopher'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(AIMessage(content=\"Plato was a philosopher\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Runnable Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class CRunnable(ABC):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.next = None\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process(self):\n",
    "        pass\n",
    "    \n",
    "    def invoke(self, data):\n",
    "        processed_data = self.process(data)\n",
    "        if self.next:\n",
    "            return self.next.invoke(processed_data)\n",
    "        return processed_data\n",
    "    \n",
    "    def __or__(self, other):\n",
    "        return CRunnableSequence(self, other)\n",
    "    \n",
    "class CRunnableSequence(CRunnable):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "        self.first.next = self.second\n",
    "        \n",
    "    def process(self, data):\n",
    "        return self.first.invoke(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capitalize(CRunnable):\n",
    "    def process(self, data):\n",
    "        return data.capitalize()\n",
    "    \n",
    "class AddExclamation(CRunnable):\n",
    "    def process(self, data):\n",
    "        return data + \"!\"\n",
    "    \n",
    "class PadStar(CRunnable):\n",
    "    def process(self, data):\n",
    "        return \"*\" + data + \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "hello!\n",
      "*hello*\n"
     ]
    }
   ],
   "source": [
    "cap = Capitalize()\n",
    "print(cap.invoke(\"hello\"))\n",
    "\n",
    "exc = AddExclamation()\n",
    "print(exc.invoke(\"hello\"))\n",
    "\n",
    "starred = PadStar()\n",
    "print(starred.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Hello!*\n"
     ]
    }
   ],
   "source": [
    "chain = cap | exc | starred\n",
    "print(chain.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.CRunnableSequence, __main__.Capitalize)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain), type(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnables in LangChainü¶ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "\n",
    "chain = RunnablePassthrough() | RunnablePassthrough() | RunnablePassthrough()\n",
    "\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_exclamation(data):\n",
    "    return data + \"!\"\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(add_exclamation) | RunnablePassthrough()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'hello', 'y': 'hello'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": RunnablePassthrough()})\n",
    "chain =  RunnablePassthrough() | parallel | RunnablePassthrough()\n",
    "\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input1': 'Hello', 'input2': 'world'}, 'y': 'World'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": lambda x: x[\"input2\"].capitalize()})\n",
    "chain =  RunnablePassthrough() | parallel | RunnablePassthrough()\n",
    "\n",
    "chain.invoke({\"input1\": \"Hello\", \"input2\": \"world\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Chains ‚õìÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'HELLO', 'y': 'World'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_key_upper(data):\n",
    "    return data.get(\"input1\", \"not found\").upper()\n",
    "\n",
    "chain = RunnableParallel({\n",
    "    \"x\": RunnablePassthrough() | RunnableLambda(find_key_upper),\n",
    "    \"y\": lambda x: x[\"input2\"].capitalize(),\n",
    "})\n",
    "\n",
    "chain.invoke({\"input1\": \"Hello\", \"input2\": \"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'NOT FOUND', 'y': 'World'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input2\": \"world\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding paths to chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'HELLO'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel({\n",
    "    \"x\": RunnablePassthrough() | RunnableLambda(find_key_upper),\n",
    "})\n",
    "\n",
    "chain.invoke({\"input1\": \"Hello\", \"input2\": \"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'HELLO', 'branch1': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_const(data):\n",
    "    return 100\n",
    "\n",
    "chain = chain.assign(branch1 = RunnablePassthrough() | RunnableLambda(assign_const))\n",
    "\n",
    "chain.invoke({\"input1\": \"Hello\", \"input2\": \"world\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractor(data):\n",
    "    return data.get(\"branch1\", \"NOT FOUND\")\n",
    "\n",
    "new_chain = RunnableLambda(extractor) | RunnableLambda(lambda x: x * 2)\n",
    "\n",
    "big_chain = chain | new_chain\n",
    "\n",
    "big_chain.invoke({\"input1\": \"Hello\", \"input2\": \"world\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='More than twice the size of the European Union, the United States has high mountains in the West and a vast central plain. \\n'), Document(page_content=\"The United States of America is the world's third largest country in size and nearly the third largest in terms of population. \\n\"), Document(page_content='There are 50 states and the District of Columbia.\\n'), Document(page_content='Located in North America, the country is bordered on the west by the Pacific Ocean and to the east by the Atlantic Ocean. \\n')]\n",
      "More than twice the size of the European Union, the United States has high mountains in the West and a vast central plain. \n",
      "\n",
      "\n",
      "The United States of America is the world's third largest country in size and nearly the third largest in terms of population. \n",
      "\n",
      "\n",
      "There are 50 states and the District of Columbia.\n",
      "\n",
      "\n",
      "Located in North America, the country is bordered on the west by the Pacific Ocean and to the east by the Atlantic Ocean. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "with open(\"data/document.txt\", \"r\") as f:\n",
    "    documents = f.readlines()\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    [Document(s) for s in documents], \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "result = retriever.invoke(\"Tell me about the history of the United States\")\n",
    "print(result)\n",
    "\n",
    "def format_ctx(data):\n",
    "    return \"\\n\\n\".join(map(lambda x: x.page_content, data))\n",
    "\n",
    "print(format_ctx(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer is Death Valley, which is at -282 feet (-86 meters).'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Based only on the following context: \n",
    "`{context}`\n",
    "What is the answer to the question - `{question}`\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | RunnableLambda(format_ctx), \"question\": RunnablePassthrough()} | \n",
    "        prompt | \n",
    "        ChatOpenAI(model=\"gpt-3.5-turbo\") |\n",
    "        StrOutputParser()\n",
    "    ) \n",
    "\n",
    "rag_chain.invoke(\"What is the deepest point in the US?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
